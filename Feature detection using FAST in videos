import cv2
import numpy as np
# Load the drone footage
video_path = "C:\\Users\\This PC\\Downloads\\Untitled video - Made with Clipchamp (1).mp4"
cap = cv2.VideoCapture(video_path)
# Check if video opened successfully
if not cap.isOpened():
    print("Error: Could not open video.")
    exit()
# Initialize FAST detector
fast = cv2.FastFeatureDetector_create()
# Parameters for lucas-kanade optical flow
lk_params = dict(winSize=(15, 15),
                 maxLevel=2,
                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

# Read the first frame
ret, old_frame = cap.read()
if not ret:
    print("Error: Could not read the first frame.")
    exit()
old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)
# Detect keypoints using FAST
keypoints = fast.detect(old_gray, None)
p0 = np.array([kp.pt for kp in keypoints], dtype=np.float32).reshape(-1, 1, 2)
# Create a mask image for drawing purposes
mask = np.zeros_like(old_frame)
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    # Calculate optical flow
    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)
    # Select good points
    good_new = p1[st == 1]
    good_old = p0[st == 1]
    # Draw the tracks
    for i, (new, old) in enumerate(zip(good_new, good_old)):
        a, b = new.ravel()
        c, d = old.ravel()
        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)
        frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 0, 255), -1)
    img = cv2.add(frame, mask)
    # Display the result
    cv2.imshow('Motion Tracking', img)
    # Break on 'q' key press
    if cv2.waitKey(30) & 0xFF == ord('q'):
        break
    # Update previous frame and points
    old_gray = frame_gray.copy()
    p0 = good_new.reshape(-1, 1, 2)

cap.release()
cv2.destroyAllWindows()
